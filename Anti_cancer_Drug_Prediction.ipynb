{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ef8700b0d4544f0a8a233e93ba73bec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e51a6e1f3d104594a95194b2e8145b2f",
              "IPY_MODEL_7968964cd26543aab6360c7819b69b4d",
              "IPY_MODEL_ed4715fa9035459cb16ec628fd09b4e7"
            ],
            "layout": "IPY_MODEL_c63ead48c6724a2ab54d3e861ebd1d7e"
          }
        },
        "e51a6e1f3d104594a95194b2e8145b2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de8f9bdbab4542dfafad7f81d5941ecf",
            "placeholder": "​",
            "style": "IPY_MODEL_05016c5e7c3d45c090690cfd3e32ef7a",
            "value": "100%"
          }
        },
        "7968964cd26543aab6360c7819b69b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af09ae50acd44ec4bf9a28421e85b748",
            "max": 25024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca97e185c45f4ea7a92861f7febf2d7e",
            "value": 25024
          }
        },
        "ed4715fa9035459cb16ec628fd09b4e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd4b5fa9aa0d412d85fabe0f5c6f7f88",
            "placeholder": "​",
            "style": "IPY_MODEL_e14f044a972a4aae98b053c4ba1f8a45",
            "value": " 25024/25024 [00:03&lt;00:00, 6446.34it/s]"
          }
        },
        "c63ead48c6724a2ab54d3e861ebd1d7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de8f9bdbab4542dfafad7f81d5941ecf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05016c5e7c3d45c090690cfd3e32ef7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af09ae50acd44ec4bf9a28421e85b748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca97e185c45f4ea7a92861f7febf2d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd4b5fa9aa0d412d85fabe0f5c6f7f88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e14f044a972a4aae98b053c4ba1f8a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb8f733e44dc415399aaaa357e77bfb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c07b6794253347eba4a6b2112768adc6",
              "IPY_MODEL_03096b32992d441288fd67af38f7ce9f",
              "IPY_MODEL_5ad4baafeaf7459383f56883ef55df72"
            ],
            "layout": "IPY_MODEL_b391c3f5b9fb4472855238ff46a4f41c"
          }
        },
        "c07b6794253347eba4a6b2112768adc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5038115df39b47efafcee127e27e5f3d",
            "placeholder": "​",
            "style": "IPY_MODEL_c34aa6693c8a47728dde4aae6600d47a",
            "value": "100%"
          }
        },
        "03096b32992d441288fd67af38f7ce9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f971f5d6a20a48ae9225e8527537963f",
            "max": 12326,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22939e823c4f45db9a0a55baff11129f",
            "value": 12326
          }
        },
        "5ad4baafeaf7459383f56883ef55df72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4d68c03e54e411db0f350000f0324a0",
            "placeholder": "​",
            "style": "IPY_MODEL_f5e66e50cd87418380766a53a5caa462",
            "value": " 12326/12326 [00:03&lt;00:00, 4408.03it/s]"
          }
        },
        "b391c3f5b9fb4472855238ff46a4f41c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5038115df39b47efafcee127e27e5f3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c34aa6693c8a47728dde4aae6600d47a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f971f5d6a20a48ae9225e8527537963f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22939e823c4f45db9a0a55baff11129f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4d68c03e54e411db0f350000f0324a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5e66e50cd87418380766a53a5caa462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Formulation\n"
      ],
      "metadata": {
        "id": "AJXd8vd5tXYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the input ? \n",
        "* the input data is a graphs that represent chemical compounds \n",
        "* The atoms of the chemical compound representing nodes and bonds as edges\n",
        "\n"
      ],
      "metadata": {
        "id": "rCmW2c5otduK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the output?\n",
        "* to determine whether the compound is either poistive or negative against non-small cell lung cancer \n",
        "* we have two classification class \n",
        "* 1 for positive class \n",
        "* 0 for negative class"
      ],
      "metadata": {
        "id": "aJmfY922tsX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What data mining function is required?\n",
        "* The data mining in this problem is Classification & Prediction"
      ],
      "metadata": {
        "id": "OPGfZw6ouJpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What could be the challenges?\n",
        "* reading SDF format\n",
        "* soliving the unbalance across the data \n",
        "* extracting important features from data file \n",
        "* using some layers to prevent overfitting."
      ],
      "metadata": {
        "id": "NJvXirvRuUcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the impact?\n",
        "* to know whether the Drug will affect the cancer or not "
      ],
      "metadata": {
        "id": "MJ8OKKW_ui32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is an ideal solution?\n",
        "the ideal solution is to clean and preprocess the data before working with it\n",
        "\n",
        "Some of the possible solutions are:\n",
        "\n",
        "* Up-sampling imbalanced data to deal with it\n",
        "*  Before dealing with the text data (that represent the atom name in the chemical compound), preprocess it."
      ],
      "metadata": {
        "id": "tuUwoiSrvJxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the experimental protocol used and how was it carried out?\n",
        "The experimental protocol involves loading the data, cleaning and preprocessing it, and then dividing the training dataset into a training_set and a validation_set. The new training_set is used to fit the model, the validation_set is used to measure the model's performance (AUROC), and the original test dataset is used to make the prediction."
      ],
      "metadata": {
        "id": "bd3M8o91wHL1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What preprocessing steps are used?\n",
        "* investigate the data and fully understand it\n",
        "* The training data should be adjusted to \"up-sample\" the positive class samples.\n",
        "* processing text data by  :\n",
        "    *    a tokenizer, build a vocabulary from the Training set.\n",
        "    *    the method pad_sequences()\n",
        "*    For each sample in gen_batch, execute prepare_single_batch.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2t6NX5kPwR-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## imports\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, precision_score, recall_score, f1_score, precision_recall_curve\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import math\n",
        "sns.set()\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from time import time\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "9lXiiOZ--5Pk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.utils import resample \n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Embedding, Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "y2WToRB0--wL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
        "from tensorflow.keras.layers import Flatten, Dropout\n",
        "from tensorflow.keras.layers import GRU, LSTM, Bidirectional"
      ],
      "metadata": {
        "id": "qWec28sX_ESt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install --quiet tf2_gnn\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "\n",
        "from tf2_gnn.layers.gnn import GNN, GNNInput\n",
        "from tf2_gnn.layers.message_passing import GNN_Edge_MLP, GNN_FiLM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWEDh3Nb_I9S",
        "outputId": "8bb11a51-9f94-4581-8248-bb13425d78b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.5/135.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.0/388.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.9/173.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for tf2_gnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "Ln3rf_ri_Pbs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## adjusting print settings for pandas \n",
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 300\n",
        "pd.options.display.max_colwidth = 100\n",
        "np.set_printoptions(threshold=2000)"
      ],
      "metadata": {
        "id": "Q5vV93WV_tKb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading The Data "
      ],
      "metadata": {
        "id": "ytbzEB1d_dk_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2J74EE_j9B-m"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#connect to drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYvExr9P9-BE",
        "outputId": "2ec98bd9-a779-4fd5-ad52-3e8cbec3f9b3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_sdf(file):\n",
        "    with open(file, 'r') as rf:\n",
        "        content = rf.read()\n",
        "        #split each sample alone by ($$$$)\n",
        "    samples = content.split('$$$$')\n",
        "    \n",
        "    def parse_sample(s):\n",
        "        lines = s.splitlines()\n",
        "        links = []\n",
        "        nodes = []\n",
        "        label = 0\n",
        "        #if the label : ==1 leave it as it is, if ==-1 make it 0.\n",
        "        for l in lines:\n",
        "            if l.strip() == '1.0':\n",
        "                label = 1\n",
        "            if l.strip() == '-1.0':\n",
        "                label = 0\n",
        "            if l.startswith('    '):\n",
        "                feature = l.split()\n",
        "                node = feature[3]\n",
        "                nodes.append(node)\n",
        "            elif l.startswith(' '):\n",
        "                lnk = l.split()\n",
        "                # edge: (from, to,) (1-based index)\n",
        "                #edge represent link between each two nodes\n",
        "                if int(lnk[0]) - 1 < len(nodes):\n",
        "                    links.append((\n",
        "                        int(lnk[0])-1, \n",
        "                        int(lnk[1])-1, # zero-based index\n",
        "                        # int(lnk[2]) ignore edge weight\n",
        "                    ))\n",
        "        return nodes, np.array(links), label\n",
        "    \n",
        "    return [parse_sample(s) for s in tqdm(samples) if len(s[0]) > 0]"
      ],
      "metadata": {
        "id": "vPbOahN5_kCh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## loading the data\n",
        "train_data = read_sdf(\"/content/drive/MyDrive/Anti-cancer/train.sdf\")\n",
        "test_data = read_sdf(\"/content/drive/MyDrive/Anti-cancer/test_x.sdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "ef8700b0d4544f0a8a233e93ba73bec0",
            "e51a6e1f3d104594a95194b2e8145b2f",
            "7968964cd26543aab6360c7819b69b4d",
            "ed4715fa9035459cb16ec628fd09b4e7",
            "c63ead48c6724a2ab54d3e861ebd1d7e",
            "de8f9bdbab4542dfafad7f81d5941ecf",
            "05016c5e7c3d45c090690cfd3e32ef7a",
            "af09ae50acd44ec4bf9a28421e85b748",
            "ca97e185c45f4ea7a92861f7febf2d7e",
            "fd4b5fa9aa0d412d85fabe0f5c6f7f88",
            "e14f044a972a4aae98b053c4ba1f8a45",
            "cb8f733e44dc415399aaaa357e77bfb4",
            "c07b6794253347eba4a6b2112768adc6",
            "03096b32992d441288fd67af38f7ce9f",
            "5ad4baafeaf7459383f56883ef55df72",
            "b391c3f5b9fb4472855238ff46a4f41c",
            "5038115df39b47efafcee127e27e5f3d",
            "c34aa6693c8a47728dde4aae6600d47a",
            "f971f5d6a20a48ae9225e8527537963f",
            "22939e823c4f45db9a0a55baff11129f",
            "c4d68c03e54e411db0f350000f0324a0",
            "f5e66e50cd87418380766a53a5caa462"
          ]
        },
        "id": "FOxznAWq-BSs",
        "outputId": "b856a809-b29f-40f1-e809-16408886006b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25024 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef8700b0d4544f0a8a233e93ba73bec0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12326 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb8f733e44dc415399aaaa357e77bfb4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# invistigating the data \n",
        "print(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_Nspre9Ab98",
        "outputId": "d1121780-9332-4daf-ad78-7157d51e3bd8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['S', 'O', 'O', 'O', 'O', 'N', 'N', 'N', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], array([[ 0,  8],\n",
            "       [ 0, 14],\n",
            "       [ 1, 10],\n",
            "       [ 2, 11],\n",
            "       [ 3,  7],\n",
            "       [ 4,  7],\n",
            "       [ 5,  9],\n",
            "       [ 5, 14],\n",
            "       [ 6, 14],\n",
            "       [ 6, 17],\n",
            "       [ 7, 22],\n",
            "       [ 8,  9],\n",
            "       [ 8, 10],\n",
            "       [ 9, 11],\n",
            "       [10, 12],\n",
            "       [11, 13],\n",
            "       [12, 13],\n",
            "       [12, 15],\n",
            "       [13, 16],\n",
            "       [15, 18],\n",
            "       [16, 19],\n",
            "       [17, 20],\n",
            "       [17, 21],\n",
            "       [18, 19],\n",
            "       [20, 23],\n",
            "       [21, 24],\n",
            "       [22, 23],\n",
            "       [22, 24]]), 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Up-Sampling\n"
      ],
      "metadata": {
        "id": "UFPQEBrCIblW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(np.array(train_data)[:,2],return_counts=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsyKtGxdIXqV",
        "outputId": "dfc445bb-5d2b-4875-c5ab-6b1b774819aa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1], dtype=object), array([23806,  1218]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting train into DataFrame\n",
        "train_df = pd.DataFrame(train_data, columns=['node','edge','label']) "
      ],
      "metadata": {
        "id": "omp14dtLIfb9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the count of 0,1 in the label column\n",
        "print(train_df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVdo6J8lIr98",
        "outputId": "c1e47f4f-b489-4927-e69c-28a5998e003d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    23806\n",
            "1     1218\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gettig negative class (label = 0)\n",
        "class_0 = train_df[train_df['label'] == 0]\n",
        "# getting possitive class (label = 1)   \n",
        "class_1 = train_df[train_df['label'] == 1] \n",
        " # resample class_1\n",
        "class_1 = resample(class_1, replace=True, n_samples=len(class_0), random_state=42)\n",
        "# get upsampled data \n",
        "upsampled_data = pd.concat([class_1, class_0])  "
      ],
      "metadata": {
        "id": "jQzXu1DJIvHY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# print the count of 0,1 in the label column after data up-sampling\n",
        "print(upsampled_data[\"label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2laeyOQI_np",
        "outputId": "727aa4ed-533b-4c21-9762-98fb18b7d1ad"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    23806\n",
            "0    23806\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert upsampled_data from DataFrame to an array \n",
        "data_upsampled = upsampled_data.to_numpy()"
      ],
      "metadata": {
        "id": "dwuSTYjyJC6V"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## splitting the Data"
      ],
      "metadata": {
        "id": "wlDh5YDpJMEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the upsampled data\n",
        "training_set, validation_set = train_test_split(data_upsampled, test_size=0.2)"
      ],
      "metadata": {
        "id": "Ndet14K5JF5a"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the data "
      ],
      "metadata": {
        "id": "yjxrrIHBJVHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet networkx\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "colors = cm.rainbow(np.linspace(0, 1, 50))"
      ],
      "metadata": {
        "id": "RWbN3PDiJTQ_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(sample):\n",
        "    G=nx.Graph()\n",
        "    nodes = sample[0]\n",
        "    edges = sample[1]\n",
        "    \n",
        "    labeldict={}\n",
        "    node_color=[]\n",
        "    for i,n in enumerate(nodes):\n",
        "        G.add_node(i)\n",
        "        labeldict[i]=n\n",
        "        node_color.append(colors[hash(n)%len(colors)])\n",
        "\n",
        "    # a list of nodes:\n",
        "    for e in edges:\n",
        "        G.add_edge(e[0], e[1])\n",
        "        \n",
        "    nx.draw(G, labels=labeldict, with_labels = True, node_color = node_color)\n",
        "    plt.show()\n",
        "    \n",
        "    return G"
      ],
      "metadata": {
        "id": "MoHHr2G4JZ5Q"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.clf()\n",
        "visualize(training_set[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "kyO2bacfJcLV",
        "outputId": "f7b54f7d-dce1-42dc-b932-4672e5d9e7de"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<networkx.classes.graph.Graph at 0x7f3f294876d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "XpbkH881Jf4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "max_vocab = 500\n",
        "max_len = 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "all_nodes = [s[0] for s in training_set]\n",
        "tokenizer = Tokenizer(num_words=max_vocab)\n",
        "tokenizer.fit_on_texts(all_nodes)"
      ],
      "metadata": {
        "id": "eVx0SxzoJds7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "def prepare_single_batch(samples):\n",
        "    sample_nodes = [s[0] for s in samples]\n",
        "    sample_nodes = tokenizer.texts_to_sequences(sample_nodes)\n",
        "    sample_nodes = pad_sequences(sample_nodes, padding='post')\n",
        "    max_nodes_len = np.shape(sample_nodes)[1]\n",
        "    edges = [s[1]+i*max_nodes_len for i,s in enumerate(samples)]\n",
        "    edges = [e for e in edges if len(e) > 0]\n",
        "    node_to_graph = [[i]*max_nodes_len for i in range(len(samples))]\n",
        "    \n",
        "    all_nodes = np.reshape(sample_nodes, -1)\n",
        "    all_edges = np.concatenate(edges)\n",
        "\n",
        "    node_to_graph = np.reshape(node_to_graph, -1)\n",
        "    return {\n",
        "        'data': all_nodes,\n",
        "        'edges': all_edges,\n",
        "        'node2grah': node_to_graph,\n",
        "    }, np.array([s[2] for s in samples])"
      ],
      "metadata": {
        "id": "6nasSJr6Jmjq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_batch(dataset, batch_size=16, repeat=False, shuffle=True):\n",
        "    while True:\n",
        "        dataset = list(dataset)\n",
        "        if shuffle:\n",
        "            random.shuffle(dataset)\n",
        "        l = len(dataset)\n",
        "        for ndx in range(0, l, batch_size):\n",
        "            batch_samples = dataset[ndx:min(ndx + batch_size, l)]\n",
        "            yield prepare_single_batch(batch_samples)\n",
        "        if not repeat:\n",
        "            break"
      ],
      "metadata": {
        "id": "w5q6n2U3Jqup"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# showing one batch:\n",
        "for train_batch in gen_batch(training_set, batch_size=4):\n",
        "    for k,v in train_batch[0].items():\n",
        "        print(k)\n",
        "        print(v)\n",
        "        pass\n",
        "    print('label', train_batch[1])\n",
        "    break\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXXtPwR1J2X5",
        "outputId": "98ed81d2-3db9-4a6d-96d8-bd8cfa7325b1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\n",
            "[5 2 2 2 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 5 2 2 2 2 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1]\n",
            "edges\n",
            "[[  0  22]\n",
            " [  1  13]\n",
            " [  2  15]\n",
            " [  3  38]\n",
            " [  3  45]\n",
            " [  4   5]\n",
            " [  4  15]\n",
            " [  5  16]\n",
            " [  6  21]\n",
            " [  6  31]\n",
            " [  6  32]\n",
            " [  7   8]\n",
            " [  7  16]\n",
            " [  8  30]\n",
            " [  9  43]\n",
            " [ 10  44]\n",
            " [ 11  12]\n",
            " [ 11  13]\n",
            " [ 11  20]\n",
            " [ 12  15]\n",
            " [ 12  18]\n",
            " [ 13  19]\n",
            " [ 14  16]\n",
            " [ 14  17]\n",
            " [ 14  24]\n",
            " [ 17  23]\n",
            " [ 17  29]\n",
            " [ 18  22]\n",
            " [ 19  27]\n",
            " [ 19  28]\n",
            " [ 20  25]\n",
            " [ 21  23]\n",
            " [ 21  26]\n",
            " [ 22  25]\n",
            " [ 24  26]\n",
            " [ 27  33]\n",
            " [ 28  34]\n",
            " [ 30  36]\n",
            " [ 30  37]\n",
            " [ 31  39]\n",
            " [ 32  40]\n",
            " [ 33  35]\n",
            " [ 34  35]\n",
            " [ 36  41]\n",
            " [ 37  42]\n",
            " [ 38  41]\n",
            " [ 38  42]\n",
            " [ 39  43]\n",
            " [ 40  44]\n",
            " [ 56  70]\n",
            " [ 71  57]\n",
            " [ 74  58]\n",
            " [ 59  83]\n",
            " [ 60  84]\n",
            " [ 85  61]\n",
            " [ 62  91]\n",
            " [ 62  94]\n",
            " [ 63  94]\n",
            " [ 64  65]\n",
            " [ 64  66]\n",
            " [ 64  72]\n",
            " [ 64  77]\n",
            " [ 65  67]\n",
            " [ 65  76]\n",
            " [ 66  68]\n",
            " [ 66  73]\n",
            " [ 66  79]\n",
            " [ 67  69]\n",
            " [ 67  70]\n",
            " [ 67  82]\n",
            " [ 68  71]\n",
            " [ 68  74]\n",
            " [ 69  75]\n",
            " [ 69  81]\n",
            " [ 70  73]\n",
            " [ 71  72]\n",
            " [ 74  83]\n",
            " [ 74  86]\n",
            " [ 75  78]\n",
            " [ 75  80]\n",
            " [ 76  80]\n",
            " [ 78  84]\n",
            " [ 78  87]\n",
            " [ 78  88]\n",
            " [ 81  85]\n",
            " [ 83  89]\n",
            " [ 84  85]\n",
            " [ 89  90]\n",
            " [ 90  91]\n",
            " [ 91  92]\n",
            " [ 91  93]\n",
            " [ 94  95]\n",
            " [112 136]\n",
            " [113 124]\n",
            " [114 127]\n",
            " [115 129]\n",
            " [116 130]\n",
            " [117 123]\n",
            " [117 127]\n",
            " [118 124]\n",
            " [118 126]\n",
            " [119 125]\n",
            " [119 127]\n",
            " [120 121]\n",
            " [120 123]\n",
            " [121 132]\n",
            " [122 123]\n",
            " [122 124]\n",
            " [122 125]\n",
            " [125 128]\n",
            " [126 129]\n",
            " [126 130]\n",
            " [126 131]\n",
            " [132 133]\n",
            " [133 134]\n",
            " [133 135]\n",
            " [134 137]\n",
            " [135 138]\n",
            " [136 137]\n",
            " [136 138]\n",
            " [200 168]\n",
            " [168 208]\n",
            " [169 202]\n",
            " [170 208]\n",
            " [170 213]\n",
            " [171 209]\n",
            " [172 210]\n",
            " [173 211]\n",
            " [174 212]\n",
            " [175 214]\n",
            " [176 217]\n",
            " [176 218]\n",
            " [177 218]\n",
            " [177 221]\n",
            " [178 219]\n",
            " [179 220]\n",
            " [180 222]\n",
            " [181 223]\n",
            " [182 183]\n",
            " [182 184]\n",
            " [182 189]\n",
            " [182 197]\n",
            " [183 185]\n",
            " [183 191]\n",
            " [183 199]\n",
            " [184 186]\n",
            " [184 192]\n",
            " [185 190]\n",
            " [185 194]\n",
            " [186 187]\n",
            " [186 195]\n",
            " [187 188]\n",
            " [187 198]\n",
            " [187 201]\n",
            " [188 193]\n",
            " [188 196]\n",
            " [189 194]\n",
            " [190 202]\n",
            " [190 204]\n",
            " [191 195]\n",
            " [192 196]\n",
            " [193 200]\n",
            " [193 205]\n",
            " [193 206]\n",
            " [198 203]\n",
            " [200 203]\n",
            " [202 207]\n",
            " [207 209]\n",
            " [208 210]\n",
            " [209 211]\n",
            " [210 212]\n",
            " [211 215]\n",
            " [211 216]\n",
            " [212 214]\n",
            " [213 214]\n",
            " [213 217]\n",
            " [218 219]\n",
            " [219 220]\n",
            " [220 222]\n",
            " [221 222]\n",
            " [221 223]]\n",
            "node2grah\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3]\n",
            "label [0 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to save the Predictions"
      ],
      "metadata": {
        "id": "wSdDUeiTKB1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  function to save the csv results\n",
        "def saveResult(y_pred, fileName):\n",
        "  submission = pd.DataFrame({'label': y_pred})\n",
        "  submission.index.name = 'id'\n",
        "  \n",
        "  submission.to_csv(fileName)"
      ],
      "metadata": {
        "id": "VHtUc44TJ4yf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Trails"
      ],
      "metadata": {
        "id": "9T_BVOKpKS-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial_1\n",
        "* Model : GNN \n",
        "* data : Not upsampled\n",
        "* Hidden_dim : 32\n",
        "* Batch_size : 16\n",
        "* epochs : 10"
      ],
      "metadata": {
        "id": "RI9k-tgtKZik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "TdPehlZvOeHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = keras.Input(batch_shape=(None,)) #Input layer for nodes (tokenized text data) \n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# configure the hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "# \n",
        "# frist load the defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "\n",
        "# Graph Neural Network layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "print('gnn_out', gnn_out)\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "print('mean:', avg)\n",
        "\n",
        "# Define the out put layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "# printing summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvxIJwaRKLdy",
        "outputId": "fabb1ecd-b629-40f3-8312-699fe39fa744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 20)           10000       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " gnn (GNN)                      (None, 32)           22464       ['embedding[0][0]',              \n",
            "                                                                  'input_2[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.segment_mean (TFOpLamb  (None, 32)          0           ['gnn[0][0]',                    \n",
            " da)                                                              'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            33          ['tf.math.segment_mean[0][0]']   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 32,497\n",
            "Trainable params: 32,497\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## compiling the model\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ],
      "metadata": {
        "id": "-hSEYLrSOh3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Fitting"
      ],
      "metadata": {
        "id": "qb7HVhqtOqTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KkD4VVlOnj-",
        "outputId": "fcec7ff2-a771-43bf-c799-b78a9733a42c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2381/2381 [==============================] - 60s 24ms/step - loss: 0.6414 - auc: 0.6792 - val_loss: 0.6139 - val_auc: 0.7264\n",
            "Epoch 2/10\n",
            "2381/2381 [==============================] - 82s 34ms/step - loss: 0.5959 - auc: 0.7443 - val_loss: 0.5841 - val_auc: 0.7625\n",
            "Epoch 3/10\n",
            "2381/2381 [==============================] - 56s 23ms/step - loss: 0.5778 - auc: 0.7651 - val_loss: 0.5701 - val_auc: 0.7789\n",
            "Epoch 4/10\n",
            "2381/2381 [==============================] - 56s 24ms/step - loss: 0.5633 - auc: 0.7822 - val_loss: 0.5614 - val_auc: 0.7952\n",
            "Epoch 5/10\n",
            "2381/2381 [==============================] - 56s 23ms/step - loss: 0.5435 - auc: 0.8014 - val_loss: 0.5351 - val_auc: 0.8127\n",
            "Epoch 6/10\n",
            "2381/2381 [==============================] - 53s 22ms/step - loss: 0.5325 - auc: 0.8122 - val_loss: 0.5364 - val_auc: 0.8178\n",
            "Epoch 7/10\n",
            "2381/2381 [==============================] - 56s 24ms/step - loss: 0.5184 - auc: 0.8236 - val_loss: 0.5201 - val_auc: 0.8291\n",
            "Epoch 8/10\n",
            "2381/2381 [==============================] - 54s 23ms/step - loss: 0.5099 - auc: 0.8308 - val_loss: 0.4994 - val_auc: 0.8400\n",
            "Epoch 9/10\n",
            "2381/2381 [==============================] - 52s 22ms/step - loss: 0.5047 - auc: 0.8348 - val_loss: 0.4962 - val_auc: 0.8430\n",
            "Epoch 10/10\n",
            "2381/2381 [==============================] - 58s 24ms/step - loss: 0.4952 - auc: 0.8416 - val_loss: 0.4894 - val_auc: 0.8473\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f03403baaf0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## saving predictions results"
      ],
      "metadata": {
        "id": "2Y1GZIWpO81m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test_data, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0QiJUG4Ou-u",
        "outputId": "ed4a1fe3-047e-48c8-a3ef-e61aa2c1322a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 5s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saveResult(y_pred, 'trial_1.csv')"
      ],
      "metadata": {
        "id": "ddnpaaFOPEMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thoughts and observations for trial 1, plan for trial 2:\n",
        "\n",
        "since our task is bioassay for anti cancer prediction , where each chemical compound is  represented as a graph i used `GNN` \n",
        "\n",
        "i used the default hyperparameters except for the hidden_dim which i set it to be 32  \n",
        "\n",
        "**The results**\n",
        "* Traing : around 84 % \n",
        "* kaggle public score : 82% \n",
        "\n",
        "oberservations : since the data where not upsaplmed the accuracy is not considered to be good enough \n",
        "\n",
        "Plans :  try using the same model but this time with upsamled data \n"
      ],
      "metadata": {
        "id": "5Q8OSFVKYG6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial_2\n",
        "* Model : GNN \n",
        "* data : upsampled\n",
        "* Hidden_dim : 32\n",
        "* Batch_size : 16\n",
        "* epochs : 10"
      ],
      "metadata": {
        "id": "ai3y-NckZhMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "VEoXDsilZtJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = keras.Input(batch_shape=(None,)) #Input layer for nodes (tokenized text data) \n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# frist load the defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"hidden_dim\"] = 32\n",
        "\n",
        "# Graph Neural Network layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "print('gnn_out', gnn_out)\n",
        "\n",
        "\n",
        "\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "print('mean:', avg)\n",
        "\n",
        "# Define the out put layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "# printing summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5uy5XAAPH7t",
        "outputId": "ae3ed0a3-a833-400c-e51a-ac30ce89cbc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_1/StatefulPartitionedCall:0', description=\"created by layer 'gnn_1'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_1/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_1'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_1/Sigmoid:0', description=\"created by layer 'dense_1'\")\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_1 (TFOpLamb  ()                  0           ['input_6[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 20)           10000       ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  ()                  0           ['tf.math.reduce_max_1[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_1 (GNN)                    (None, 32)           22464       ['embedding_1[0][0]',            \n",
            "                                                                  'input_5[0][0]',                \n",
            "                                                                  'input_6[0][0]',                \n",
            "                                                                  'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_1 (TFOpLa  (None, 32)          0           ['gnn_1[0][0]',                  \n",
            " mbda)                                                            'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            33          ['tf.math.segment_mean_1[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 32,497\n",
            "Trainable params: 32,497\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model compiling\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ],
      "metadata": {
        "id": "mZ6yrynyZwyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting the model"
      ],
      "metadata": {
        "id": "TkDzZ-2ZZ3PQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5QtOrMIZ1iK",
        "outputId": "273e3ca8-3be0-4cd4-cdf7-ee23cfd02b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2381/2381 [==============================] - 73s 29ms/step - loss: 0.6372 - auc: 0.6857 - val_loss: 0.6050 - val_auc: 0.7338\n",
            "Epoch 2/10\n",
            "2381/2381 [==============================] - 64s 27ms/step - loss: 0.5942 - auc: 0.7474 - val_loss: 0.5769 - val_auc: 0.7640\n",
            "Epoch 3/10\n",
            "2381/2381 [==============================] - 53s 22ms/step - loss: 0.5740 - auc: 0.7715 - val_loss: 0.5649 - val_auc: 0.7867\n",
            "Epoch 4/10\n",
            "2381/2381 [==============================] - 54s 23ms/step - loss: 0.5555 - auc: 0.7893 - val_loss: 0.5378 - val_auc: 0.8031\n",
            "Epoch 5/10\n",
            "2381/2381 [==============================] - 61s 26ms/step - loss: 0.5379 - auc: 0.8059 - val_loss: 0.5194 - val_auc: 0.8217\n",
            "Epoch 6/10\n",
            "2381/2381 [==============================] - 53s 22ms/step - loss: 0.5246 - auc: 0.8172 - val_loss: 0.5210 - val_auc: 0.8249\n",
            "Epoch 7/10\n",
            "2381/2381 [==============================] - 55s 23ms/step - loss: 0.5186 - auc: 0.8237 - val_loss: 0.5130 - val_auc: 0.8311\n",
            "Epoch 8/10\n",
            "2381/2381 [==============================] - 59s 25ms/step - loss: 0.5135 - auc: 0.8266 - val_loss: 0.5009 - val_auc: 0.8395\n",
            "Epoch 9/10\n",
            "2381/2381 [==============================] - 61s 26ms/step - loss: 0.5075 - auc: 0.8318 - val_loss: 0.4976 - val_auc: 0.8397\n",
            "Epoch 10/10\n",
            "2381/2381 [==============================] - 53s 22ms/step - loss: 0.5038 - auc: 0.8347 - val_loss: 0.5037 - val_auc: 0.8362\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f032daadf40>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## saving predictions results"
      ],
      "metadata": {
        "id": "5iMe6mGnaEuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test_data, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgZ3f3lIZ6hK",
        "outputId": "1fd53c58-ce71-4243-9951-134c9e6cb2e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 5s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saveResult(y_pred, 'trial_2.csv')"
      ],
      "metadata": {
        "id": "h9x0Uo4xaKVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thoughts and observations for trial 2, plan for trial 3:\n",
        "\n",
        "Using the same strcture of the previus model and the only diffrence was only using upsampling data \n",
        "\n",
        "**The results**\n",
        "* Training : 83.47%  \n",
        "* kaggle public score : 79.30%\n",
        "\n",
        "oberservations : the accuracy decreased a little bit \n",
        "\n",
        "Plans :  try using the same model and upsampled data one more time but this time trying to use  one of the `GCN aggregation mechanisms` by tuning the `message_passing mechanisms` and `configure the message passing style to be GGNN`"
      ],
      "metadata": {
        "id": "KaRMS6zleIAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial_3\n",
        "* Model : GNN \n",
        "* data : upsampled\n",
        "* Hidden_dim : 32\n",
        "* Batch_size : 16\n",
        "* epochs : 10\n",
        "\n",
        "**Tuning**\n",
        "* message_calculation_class  : GGNN "
      ],
      "metadata": {
        "id": "lo3qyL77fszZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "9MtEDc0RgEpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# frist load the defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "\n",
        "params[\"hidden_dim\"] = 32\n",
        "\n",
        "params['message_calculation_class'] = 'GGNN'\n",
        "\n",
        "# Implements a deep Graph Neural Network\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "\n",
        "# Define the out put layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs={\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTu9wnBpaWD6",
        "outputId": "a19298ee-bf3c-4e94-f3d7-763c8980fc27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_2 (TFOpLamb  ()                  0           ['input_9[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 20)           10000       ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  ()                  0           ['tf.math.reduce_max_2[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_2 (GNN)                    (None, 32)           47808       ['embedding_2[0][0]',            \n",
            "                                                                  'input_8[0][0]',                \n",
            "                                                                  'input_9[0][0]',                \n",
            "                                                                  'tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_2 (TFOpLa  (None, 32)          0           ['gnn_2[0][0]',                  \n",
            " mbda)                                                            'input_9[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            33          ['tf.math.segment_mean_2[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 57,841\n",
            "Trainable params: 57,841\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## compiling model\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ],
      "metadata": {
        "id": "hOyS8LkjgPGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting the model"
      ],
      "metadata": {
        "id": "UzkKaX1fgTha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "# training the model for 5 epochs\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHBcsRcWgSay",
        "outputId": "04a67333-81ae-41d6-cf2a-fa39bf6e587c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2381/2381 [==============================] - 111s 44ms/step - loss: 0.6406 - auc: 0.6765 - val_loss: 0.6061 - val_auc: 0.7296\n",
            "Epoch 2/10\n",
            "2381/2381 [==============================] - 91s 38ms/step - loss: 0.5861 - auc: 0.7575 - val_loss: 0.5564 - val_auc: 0.7900\n",
            "Epoch 3/10\n",
            "2381/2381 [==============================] - 88s 37ms/step - loss: 0.5371 - auc: 0.8058 - val_loss: 0.5269 - val_auc: 0.8290\n",
            "Epoch 4/10\n",
            "2381/2381 [==============================] - 85s 36ms/step - loss: 0.5040 - auc: 0.8339 - val_loss: 0.4742 - val_auc: 0.8575\n",
            "Epoch 5/10\n",
            "2381/2381 [==============================] - 87s 36ms/step - loss: 0.4765 - auc: 0.8536 - val_loss: 0.4590 - val_auc: 0.8680\n",
            "Epoch 6/10\n",
            "2381/2381 [==============================] - 88s 37ms/step - loss: 0.4585 - auc: 0.8657 - val_loss: 0.4538 - val_auc: 0.8746\n",
            "Epoch 7/10\n",
            "2381/2381 [==============================] - 88s 37ms/step - loss: 0.4392 - auc: 0.8783 - val_loss: 0.4270 - val_auc: 0.8875\n",
            "Epoch 8/10\n",
            "2381/2381 [==============================] - 87s 36ms/step - loss: 0.4221 - auc: 0.8882 - val_loss: 0.4036 - val_auc: 0.9017\n",
            "Epoch 9/10\n",
            "2381/2381 [==============================] - 90s 38ms/step - loss: 0.4052 - auc: 0.8976 - val_loss: 0.4134 - val_auc: 0.8997\n",
            "Epoch 10/10\n",
            "2381/2381 [==============================] - 88s 37ms/step - loss: 0.3885 - auc: 0.9061 - val_loss: 0.3735 - val_auc: 0.9141\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f032c202850>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## saving predictions results"
      ],
      "metadata": {
        "id": "-kduCzblgcL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test_data, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRsWN6SMgYtj",
        "outputId": "bbab8283-630f-4639-f27b-f0c46def056a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 10s 12ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saveResult(y_pred, 'trial_3.csv')"
      ],
      "metadata": {
        "id": "DJ8zZq6ygg8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thoughts and observations for trial 3, plan for trial 4:\n",
        "\n",
        "Using the same strcture of the previus model and the only diffrence was only Tuning the model by setting message passing style to GGNN \n",
        "\n",
        "**The results**\n",
        "* Training : 90.61%  \n",
        "* kaggle public score : 86.60%\n",
        "\n",
        "oberservations : THe accuracy is much better than the two previous trails \n",
        "\n",
        "Plans :  try using the same model and upsampled data one more time but this time trying try another `GCN aggregation mechanisms` by tuning the `message_passing mechanisms` and `configure the message passing style to be RGCN`"
      ],
      "metadata": {
        "id": "Ca8KxJoLkg1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial_4\n",
        "* Model : GNN \n",
        "* data : upsampled\n",
        "* Hidden_dim : 32\n",
        "* Batch_size : 16\n",
        "* epochs : 10\n",
        "\n",
        "**Tuning**\n",
        "* message_calculation_class  : RGCN "
      ],
      "metadata": {
        "id": "2GkTbQaylBZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "y5xcfSxtlFpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# configure the hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "# \n",
        "# frist load the defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "# configures the message passing style to be RGCN (Relational Graph Convolutional Networks)\n",
        "params['message_calculation_class'] = 'RGCN'\n",
        "\n",
        "# Implements a deep Graph Neural Network\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "\n",
        "# Define the output layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt5PGmsHgkqt",
        "outputId": "c01b2092-72d7-4cf5-cba7-18699f723f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_3 (TFOpLamb  ()                  0           ['input_12[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 20)           10000       ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  ()                  0           ['tf.math.reduce_max_3[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_3 (GNN)                    (None, 32)           22464       ['embedding_3[0][0]',            \n",
            "                                                                  'input_11[0][0]',               \n",
            "                                                                  'input_12[0][0]',               \n",
            "                                                                  'tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_3 (TFOpLa  (None, 32)          0           ['gnn_3[0][0]',                  \n",
            " mbda)                                                            'input_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1)            33          ['tf.math.segment_mean_3[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 32,497\n",
            "Trainable params: 32,497\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model compiling\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ],
      "metadata": {
        "id": "XO7W2PtglJ82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting the model"
      ],
      "metadata": {
        "id": "Dgm0wwL0lOW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "# training the model for 5 epochs\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CztVN3qlNSt",
        "outputId": "8e2f6f75-04d9-4e51-c2b0-5838876429cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2381/2381 [==============================] - 71s 28ms/step - loss: 0.6369 - auc: 0.6875 - val_loss: 0.6322 - val_auc: 0.7287\n",
            "Epoch 2/10\n",
            "2381/2381 [==============================] - 53s 22ms/step - loss: 0.6009 - auc: 0.7406 - val_loss: 0.5931 - val_auc: 0.7522\n",
            "Epoch 3/10\n",
            "2381/2381 [==============================] - 56s 23ms/step - loss: 0.5888 - auc: 0.7553 - val_loss: 0.5777 - val_auc: 0.7719\n",
            "Epoch 4/10\n",
            "2381/2381 [==============================] - 53s 22ms/step - loss: 0.5713 - auc: 0.7723 - val_loss: 0.5642 - val_auc: 0.7810\n",
            "Epoch 5/10\n",
            "2381/2381 [==============================] - 55s 23ms/step - loss: 0.5594 - auc: 0.7845 - val_loss: 0.5423 - val_auc: 0.7980\n",
            "Epoch 6/10\n",
            "2381/2381 [==============================] - 57s 24ms/step - loss: 0.5490 - auc: 0.7948 - val_loss: 0.5404 - val_auc: 0.8045\n",
            "Epoch 7/10\n",
            "2381/2381 [==============================] - 59s 25ms/step - loss: 0.5356 - auc: 0.8075 - val_loss: 0.5348 - val_auc: 0.8113\n",
            "Epoch 8/10\n",
            "2381/2381 [==============================] - 54s 23ms/step - loss: 0.5248 - auc: 0.8168 - val_loss: 0.5135 - val_auc: 0.8313\n",
            "Epoch 9/10\n",
            "2381/2381 [==============================] - 58s 25ms/step - loss: 0.5169 - auc: 0.8253 - val_loss: 0.5149 - val_auc: 0.8314\n",
            "Epoch 10/10\n",
            "2381/2381 [==============================] - 56s 23ms/step - loss: 0.5050 - auc: 0.8342 - val_loss: 0.4999 - val_auc: 0.8413\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0326d1df70>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## saving predictions results"
      ],
      "metadata": {
        "id": "m_QpfqnylYbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test_data, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T_a_fX1lUG9",
        "outputId": "6d041650-5e14-4bfb-ed2d-76b3aaa9aeab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 5s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saveResult(y_pred, 'trial_4.csv')"
      ],
      "metadata": {
        "id": "-SmbdFMOlbhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thoughts and observations for trial 4, plan for trial 5:\n",
        "\n",
        "Using the same strcture of the previus model and the only diffrence was only Tuning the model by setting message passing style to RGCN \n",
        "\n",
        "**The results**\n",
        "* Training : 83.42%  \n",
        "* kaggle public score : 80.48%\n",
        "\n",
        "oberservations : The accuracy is not as good as the previous one a drastic decrease happened here 😞\n",
        "\n",
        "Plans :  try using the same model and upsampled data one more time but this time trying try another `GCN aggregation mechanisms` by tuning the `message_passing mechanisms` and `configure the message passing style to be RGAT` and by setting the and setting the number of parallel (independent) weighted sums that are computed `num_heads` to be 5"
      ],
      "metadata": {
        "id": "M5_xuwl8ohKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial_5\n",
        "* Model : GNN \n",
        "* data : upsampled\n",
        "* Hidden_dim : 32\n",
        "* Batch_size : 16\n",
        "* epochs : 10\n",
        "\n",
        "**Tuning**\n",
        "* message_calculation_class  : RGAT\n",
        "* num_heads: 5"
      ],
      "metadata": {
        "id": "-sH9f33QpQ3_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "UREJsBmOpfFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# configure the hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "# \n",
        "# frist load the defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "# configures the message passing style to be RGAT (Relational Graph Attention Networks)\n",
        "params['message_calculation_class'] = 'RGAT'\n",
        "# configures the number of parallel (independent) weighted sums that are computed, whose results are concatenated to obtain the final result.\n",
        "params[\"num_heads\"] = 4\n",
        "\n",
        "# Implements a deep Graph Neural Network\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "\n",
        "# Define the out put layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dqBX1BkleRK",
        "outputId": "f69c66b1-6d20-4ee3-cf57-256cf5ff1b20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_13 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_4 (TFOpLamb  ()                  0           ['input_15[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, 20)           10000       ['input_13[0][0]']               \n",
            "                                                                                                  \n",
            " input_14 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  ()                  0           ['tf.math.reduce_max_4[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_4 (GNN)                    (None, 32)           22720       ['embedding_4[0][0]',            \n",
            "                                                                  'input_14[0][0]',               \n",
            "                                                                  'input_15[0][0]',               \n",
            "                                                                  'tf.__operators__.add_4[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_4 (TFOpLa  (None, 32)          0           ['gnn_4[0][0]',                  \n",
            " mbda)                                                            'input_15[0][0]']               \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 1)            33          ['tf.math.segment_mean_4[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 32,753\n",
            "Trainable params: 32,753\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## compiling the model\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ],
      "metadata": {
        "id": "iLnHGVnJpiP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting The model"
      ],
      "metadata": {
        "id": "fXYb7gZxpoIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E36l_iB5pnQ-",
        "outputId": "8727060f-870a-4a33-faa5-7d069873b8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2381/2381 [==============================] - 103s 40ms/step - loss: 0.6411 - auc: 0.6782 - val_loss: 0.6239 - val_auc: 0.7164\n",
            "Epoch 2/10\n",
            "2381/2381 [==============================] - 80s 34ms/step - loss: 0.6029 - auc: 0.7390 - val_loss: 0.5932 - val_auc: 0.7567\n",
            "Epoch 3/10\n",
            "2381/2381 [==============================] - 79s 33ms/step - loss: 0.5834 - auc: 0.7629 - val_loss: 0.5810 - val_auc: 0.7769\n",
            "Epoch 4/10\n",
            "2381/2381 [==============================] - 82s 34ms/step - loss: 0.5604 - auc: 0.7876 - val_loss: 0.5407 - val_auc: 0.8063\n",
            "Epoch 5/10\n",
            "2381/2381 [==============================] - 81s 34ms/step - loss: 0.5389 - auc: 0.8080 - val_loss: 0.5267 - val_auc: 0.8264\n",
            "Epoch 6/10\n",
            "2381/2381 [==============================] - 76s 32ms/step - loss: 0.5230 - auc: 0.8216 - val_loss: 0.5132 - val_auc: 0.8322\n",
            "Epoch 7/10\n",
            "2381/2381 [==============================] - 77s 32ms/step - loss: 0.5103 - auc: 0.8316 - val_loss: 0.5105 - val_auc: 0.8427\n",
            "Epoch 8/10\n",
            "2381/2381 [==============================] - 77s 32ms/step - loss: 0.4983 - auc: 0.8411 - val_loss: 0.4914 - val_auc: 0.8502\n",
            "Epoch 9/10\n",
            "2381/2381 [==============================] - 76s 32ms/step - loss: 0.4897 - auc: 0.8468 - val_loss: 0.4835 - val_auc: 0.8600\n",
            "Epoch 10/10\n",
            "2381/2381 [==============================] - 76s 32ms/step - loss: 0.4801 - auc: 0.8539 - val_loss: 0.4706 - val_auc: 0.8657\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f03278a78e0>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## saving predictions results"
      ],
      "metadata": {
        "id": "_z0M3khepyVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test_data, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6I8ILs9puXG",
        "outputId": "d951f507-8bbb-4604-d4b7-73c81ced0b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 10s 13ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saveResult(y_pred, 'trial_5.csv')"
      ],
      "metadata": {
        "id": "0V_z0A9Dp3vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thoughts and observations for trial 5, plan for trial 6:\n",
        "\n",
        "Using the same strcture of the previus model and the only diffrence was only Tuning the model by setting message passing style to RGIN \n",
        "\n",
        "**The results**\n",
        "* Training : 85.39%  \n",
        "* kaggle public score : 81.05%\n",
        "\n",
        "oberservations : The accuracy is slightly better than the previous ine but not the best result .\n",
        "\n",
        "Plans :  try using the same model and upsampled data one more time but this time trying try another `GCN aggregation mechanisms` by tuning the `message_passing mechanisms` and `configure the message passing style to be RGIN` and setting `num_aggr_MLP_hidden_layers` To 2 "
      ],
      "metadata": {
        "id": "jZgaIWYQtrfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial_6\n",
        "* Model : GNN \n",
        "* data : upsampled\n",
        "* Hidden_dim : 32\n",
        "* Batch_size : 16\n",
        "* epochs : 10\n",
        "\n",
        "**Tuning**\n",
        "* message_calculation_class : RGIN\n",
        "* num_aggr_MLP_hidden_layers : 2"
      ],
      "metadata": {
        "id": "brVb9W1yuj6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "sMsX2Di1vJPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# configure the hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "# \n",
        "# frist load the defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "# configures the message passing style to be RGIN (Relational Graph Isomorphism Networks)\n",
        "params['message_calculation_class'] = 'RGIN'\n",
        "params['num_aggr_MLP_hidden_layers'] = 2\n",
        "\n",
        "# Implements a deep Graph Neural Network\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "\n",
        "# Define the out put layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "model.summary()\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm8mpPckp4At",
        "outputId": "6cb5f066-d8ad-43fa-baef-65129e3166f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_18 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_16 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_5 (TFOpLamb  ()                  0           ['input_18[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, 20)           10000       ['input_16[0][0]']               \n",
            "                                                                                                  \n",
            " input_17 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  ()                  0           ['tf.math.reduce_max_5[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_5 (GNN)                    (None, 32)           34752       ['embedding_5[0][0]',            \n",
            "                                                                  'input_17[0][0]',               \n",
            "                                                                  'input_18[0][0]',               \n",
            "                                                                  'tf.__operators__.add_5[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_5 (TFOpLa  (None, 32)          0           ['gnn_5[0][0]',                  \n",
            " mbda)                                                            'input_18[0][0]']               \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            33          ['tf.math.segment_mean_5[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 44,785\n",
            "Trainable params: 44,785\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## model compiling\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ],
      "metadata": {
        "id": "KZKeSl-HvL5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting the model"
      ],
      "metadata": {
        "id": "fbS7zZ0AvRR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xyr6JXcOvPit",
        "outputId": "95afc1f0-31a1-48b1-e747-aabff76567d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2381/2381 [==============================] - 85s 33ms/step - loss: 0.6458 - auc: 0.6697 - val_loss: 0.6080 - val_auc: 0.7325\n",
            "Epoch 2/10\n",
            "2381/2381 [==============================] - 71s 30ms/step - loss: 0.6017 - auc: 0.7397 - val_loss: 0.6259 - val_auc: 0.7464\n",
            "Epoch 3/10\n",
            "2381/2381 [==============================] - 65s 27ms/step - loss: 0.5824 - auc: 0.7636 - val_loss: 0.5857 - val_auc: 0.7740\n",
            "Epoch 4/10\n",
            "2381/2381 [==============================] - 66s 28ms/step - loss: 0.5676 - auc: 0.7795 - val_loss: 0.5717 - val_auc: 0.7864\n",
            "Epoch 5/10\n",
            "2381/2381 [==============================] - 69s 29ms/step - loss: 0.5473 - auc: 0.7994 - val_loss: 0.5435 - val_auc: 0.8027\n",
            "Epoch 6/10\n",
            "2381/2381 [==============================] - 66s 28ms/step - loss: 0.5309 - auc: 0.8153 - val_loss: 0.5246 - val_auc: 0.8322\n",
            "Epoch 7/10\n",
            "2381/2381 [==============================] - 67s 28ms/step - loss: 0.5167 - auc: 0.8264 - val_loss: 0.4986 - val_auc: 0.8416\n",
            "Epoch 8/10\n",
            "2381/2381 [==============================] - 66s 28ms/step - loss: 0.5136 - auc: 0.8290 - val_loss: 0.5059 - val_auc: 0.8435\n",
            "Epoch 9/10\n",
            "2381/2381 [==============================] - 71s 30ms/step - loss: 0.5185 - auc: 0.8251 - val_loss: 0.5527 - val_auc: 0.8244\n",
            "Epoch 10/10\n",
            "2381/2381 [==============================] - 65s 27ms/step - loss: 0.5056 - auc: 0.8359 - val_loss: 0.4778 - val_auc: 0.8575\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f032565d3a0>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## saving predictions results"
      ],
      "metadata": {
        "id": "uGGbaLuvvX9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test_data, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh_yHILLvVBF",
        "outputId": "2b7a90b0-0ed6-4155-a4a4-7b0099cf6f55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 8s 10ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saveResult(y_pred, 'trial_6.csv')"
      ],
      "metadata": {
        "id": "OOf2sDbHvbnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thoughts and observations for trial 6, plan for trial 7:\n",
        "\n",
        "Using the same strcture of the previus model and the only diffrence was only Tuning the model by setting message passing style to GNN_Edge_MLP \n",
        "\n",
        "**The results**\n",
        "* Training : 83.59%  \n",
        "* kaggle public score : 82.35%\n",
        "\n",
        "oberservations : The accuracy is slightly better than the previous ine but not the best result which was achived by [GGNN] .\n",
        "\n",
        "Plans :  try using the same model and upsampled data one more time but this time trying try another `GCN aggregation mechanisms` by tuning the `message_passing mechanisms` and `configure the message passing style to be GNN_Edge_MLP` and Tuning the parameters required by  `GNN_Edge_MLP`"
      ],
      "metadata": {
        "id": "DPitltlKy3tB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial_7\n",
        "* Model : GNN \n",
        "* data : upsampled\n",
        "* Hidden_dim : 32\n",
        "* Batch_size : 16\n",
        "* epochs : 10\n",
        "\n",
        "**Tuning**\n",
        "* message_calculation_class : GNN_Edge_MLP\n",
        "* and adjusting it's hyperparameters"
      ],
      "metadata": {
        "id": "ePXgk47Yzeq5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "alQsDG2gsnea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# configure the hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "# \n",
        "# frist load the defualt hyperparameters of GNN_Edge_MLP\n",
        "params = GNN_Edge_MLP.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "\n",
        "# configuring the parameters that needed by GNN_Edge_MLP\n",
        "params['num_layers'] = 4\n",
        "params['dense_every_num_layers'] = 2\n",
        "params['residual_every_num_layers'] = 2\n",
        "params['use_inter_layer_layernorm'] = 2\n",
        "params['initial_node_representation_activation'] = 'tanh'\n",
        "params['dense_intermediate_layer_activation'] = 'tanh'\n",
        "params['message_calculation_class'] = 'RGCN'\n",
        "params['global_exchange_mode'] = 'gru'   \n",
        "params['global_exchange_every_num_layers'] = 1000\n",
        "params['global_exchange_weighting_fun'] = 'softmax'\n",
        "params['global_exchange_num_heads'] = 4\n",
        "params['global_exchange_dropout_rate'] = 0.2\n",
        "params['layer_input_dropout_rate'] = 0.2\n",
        "\n",
        "# Implements a deep Graph Neural Network\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "\n",
        "# Define the out put layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "H1xDQQmlveai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "190bc166-0734-4893-9e87-a2d21873e3ed"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max (TFOpLambda  ()                  0           ['input_6[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 20)           10000       ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " gnn (GNN)                      (None, 32)           15232       ['embedding[0][0]',              \n",
            "                                                                  'input_5[0][0]',                \n",
            "                                                                  'input_6[0][0]',                \n",
            "                                                                  'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.segment_mean (TFOpLamb  (None, 32)          0           ['gnn[0][0]',                    \n",
            " da)                                                              'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            33          ['tf.math.segment_mean[0][0]']   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,265\n",
            "Trainable params: 25,265\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## model compiling\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ],
      "metadata": {
        "id": "GXJfPQKqsz_6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model fitting"
      ],
      "metadata": {
        "id": "eFKNgGBCtF4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "# training the model for 5 epochs\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-P19b8MtEf7",
        "outputId": "27a2c0eb-90da-4e02-836a-4e28fcb23ae2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2381/2381 [==============================] - 89s 36ms/step - loss: 0.6156 - auc: 0.7198 - val_loss: 0.5704 - val_auc: 0.7704\n",
            "Epoch 2/10\n",
            "2381/2381 [==============================] - 74s 31ms/step - loss: 0.5678 - auc: 0.7800 - val_loss: 0.5518 - val_auc: 0.7955\n",
            "Epoch 3/10\n",
            "2381/2381 [==============================] - 73s 31ms/step - loss: 0.5534 - auc: 0.7966 - val_loss: 0.5310 - val_auc: 0.8152\n",
            "Epoch 4/10\n",
            "2381/2381 [==============================] - 66s 28ms/step - loss: 0.5411 - auc: 0.8103 - val_loss: 0.5226 - val_auc: 0.8223\n",
            "Epoch 5/10\n",
            "2381/2381 [==============================] - 75s 32ms/step - loss: 0.5293 - auc: 0.8197 - val_loss: 0.5098 - val_auc: 0.8348\n",
            "Epoch 6/10\n",
            "2381/2381 [==============================] - 57s 24ms/step - loss: 0.5210 - auc: 0.8269 - val_loss: 0.5048 - val_auc: 0.8443\n",
            "Epoch 7/10\n",
            "2381/2381 [==============================] - 63s 26ms/step - loss: 0.5117 - auc: 0.8351 - val_loss: 0.5012 - val_auc: 0.8495\n",
            "Epoch 8/10\n",
            "2381/2381 [==============================] - 64s 27ms/step - loss: 0.5080 - auc: 0.8375 - val_loss: 0.4815 - val_auc: 0.8552\n",
            "Epoch 9/10\n",
            "2381/2381 [==============================] - 60s 25ms/step - loss: 0.4989 - auc: 0.8442 - val_loss: 0.4798 - val_auc: 0.8567\n",
            "Epoch 10/10\n",
            "2381/2381 [==============================] - 70s 29ms/step - loss: 0.4964 - auc: 0.8466 - val_loss: 0.4855 - val_auc: 0.8596\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3f259bf310>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## saving predictions results"
      ],
      "metadata": {
        "id": "qnoTPKvCtM5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test_data, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxF608IntJRB",
        "outputId": "2eebdb2b-50f8-4861-85f7-09848812c04f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 6s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saveResult(y_pred, 'trial_7.csv')"
      ],
      "metadata": {
        "id": "P_-OyQGgtRuk"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thoughts and observations for trial 7, plan for trial 8:\n",
        "\n",
        "Using the same strcture of the previus model and the only diffrence was only Tuning the model by setting message passing style to GNN_FiLM \n",
        "\n",
        "**The results**\n",
        "* Training : 84.66%  \n",
        "* kaggle public score : 85.20%\n",
        "\n",
        "oberservations : The accuracy is slightly better than the previous ine but not the best result which was achived by [GGNN] .\n",
        "\n",
        "Plans :  try using the same model and upsampled data one more time but this time trying try another `GCN aggregation mechanisms` by tuning the `message_passing mechanisms` and `configure the message passing style to be GNN_FiLM` and Tuning the parameters required by  `GNN_FiLM`"
      ],
      "metadata": {
        "id": "TlOHB4doxQmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial_8\n",
        "* Model : GNN \n",
        "* data : upsampled\n",
        "* Hidden_dim : 32\n",
        "* Batch_size : 16\n",
        "* epochs : 10\n",
        "\n",
        "**Tuning**\n",
        "* message_calculation_class : GNN_FiLM\n",
        "* and adjusting it's hyperparameters"
      ],
      "metadata": {
        "id": "jhD49QMfxv3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "jEHLvl8nx2t1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# configure the hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "# \n",
        "# frist load the defualt hyperparameters of GNN_FiLM\n",
        "params = GNN_FiLM.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "# configures the parameters that needed by GNN_FiLM\n",
        "params['num_layers'] = 4\n",
        "params['dense_every_num_layers'] = 2\n",
        "params['residual_every_num_layers'] = 2\n",
        "params['use_inter_layer_layernorm'] = 2\n",
        "params['initial_node_representation_activation'] = 'tanh'\n",
        "params['dense_intermediate_layer_activation'] = 'tanh'\n",
        "params['message_calculation_class'] = 'RGCN'\n",
        "params['global_exchange_mode'] = 'gru'   # has to be one of 'mean', 'mlp', 'gru'!\n",
        "params['global_exchange_every_num_layers'] = 1000\n",
        "params['global_exchange_weighting_fun'] = 'softmax'\n",
        "params['global_exchange_num_heads'] = 4\n",
        "params['global_exchange_dropout_rate'] = 0.2\n",
        "params['layer_input_dropout_rate'] = 0.2\n",
        "\n",
        "# Implements a deep Graph Neural Network\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "\n",
        "# Define the out put layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ftdqEfYtVHH",
        "outputId": "f31a6517-24aa-4593-fda4-481a0f48eaaf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_1 (TFOpLamb  ()                  0           ['input_9[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 20)           10000       ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  ()                  0           ['tf.math.reduce_max_1[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_1 (GNN)                    (None, 32)           7040        ['embedding_1[0][0]',            \n",
            "                                                                  'input_8[0][0]',                \n",
            "                                                                  'input_9[0][0]',                \n",
            "                                                                  'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_1 (TFOpLa  (None, 32)          0           ['gnn_1[0][0]',                  \n",
            " mbda)                                                            'input_9[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            33          ['tf.math.segment_mean_1[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17,073\n",
            "Trainable params: 17,073\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## compiling model\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ],
      "metadata": {
        "id": "U3rAhvvGx6Ih"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Fitting"
      ],
      "metadata": {
        "id": "LS_7huoXx_rB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCCeIg0qx-0f",
        "outputId": "f35cd5b6-e369-4c89-b952-6c658babc5ac"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2381/2381 [==============================] - 54s 23ms/step - loss: 0.6125 - auc: 0.7280 - val_loss: 0.5902 - val_auc: 0.7504\n",
            "Epoch 2/10\n",
            "2381/2381 [==============================] - 60s 25ms/step - loss: 0.5940 - auc: 0.7525 - val_loss: 0.5769 - val_auc: 0.7657\n",
            "Epoch 3/10\n",
            "2381/2381 [==============================] - 52s 22ms/step - loss: 0.5826 - auc: 0.7652 - val_loss: 0.5575 - val_auc: 0.7898\n",
            "Epoch 4/10\n",
            "2381/2381 [==============================] - 60s 25ms/step - loss: 0.5761 - auc: 0.7735 - val_loss: 0.5547 - val_auc: 0.7947\n",
            "Epoch 5/10\n",
            "2381/2381 [==============================] - 53s 22ms/step - loss: 0.5697 - auc: 0.7801 - val_loss: 0.5485 - val_auc: 0.7997\n",
            "Epoch 6/10\n",
            "2381/2381 [==============================] - 56s 24ms/step - loss: 0.5603 - auc: 0.7912 - val_loss: 0.5402 - val_auc: 0.8063\n",
            "Epoch 7/10\n",
            "2381/2381 [==============================] - 51s 22ms/step - loss: 0.5581 - auc: 0.7949 - val_loss: 0.5552 - val_auc: 0.8117\n",
            "Epoch 8/10\n",
            "2381/2381 [==============================] - 61s 25ms/step - loss: 0.5545 - auc: 0.7987 - val_loss: 0.5343 - val_auc: 0.8143\n",
            "Epoch 9/10\n",
            "2381/2381 [==============================] - 53s 22ms/step - loss: 0.5514 - auc: 0.8003 - val_loss: 0.5281 - val_auc: 0.8187\n",
            "Epoch 10/10\n",
            "2381/2381 [==============================] - 53s 22ms/step - loss: 0.5484 - auc: 0.8038 - val_loss: 0.5268 - val_auc: 0.8246\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3f11cb98a0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## saving predictions results\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fIEgf5UAyIZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test_data, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LvtzmCOyD6_",
        "outputId": "1bb3f607-9cb1-48e9-9814-2749f4644f17"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 8s 10ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saveResult(y_pred, 'trial_8.csv')"
      ],
      "metadata": {
        "id": "W3ChP0etyLr6"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thoughts and observations for trial 8, plan for trial 9:\n",
        "\n",
        "Using the same strcture of the previus model and the only diffrence was only Tuning the model by setting message passing style to GNN_FiLM \n",
        "\n",
        "**The results**\n",
        "* Training : 80.38%  \n",
        "* kaggle public score : 81.58%\n",
        "\n",
        "oberservations : Since i have applied all the possible GCN `message_passing_mechanisims` in the previous 8 trials the best results ahcived so far was by :  \n",
        "* Trial_3  with kaggle public score of 86.60%\n",
        "* Trial_7  with kaggle public score of  85.20%\n",
        "\n",
        "Plans :  In the last 2 trials try to adjust the hyperparameters for these model in order to get a better accuracy out of them."
      ],
      "metadata": {
        "id": "v7eLkDVD1AHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial_9\n",
        "* Model : GNN \n",
        "* data : upsampled\n",
        "* Hidden_dim : 62 [was 32]\n",
        "* Batch_size : 16\n",
        "* epochs : 10\n",
        "\n",
        "**Tuning**\n",
        "* message_calculation_class : GCNN [Trial_3 Tuning]\n"
      ],
      "metadata": {
        "id": "CDJI9cDa2xOO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "tsROFlhm3Azo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# configure the hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "# \n",
        "# frist load the defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 64\n",
        "# configures the message passing style to be GGNN (Gated Graph Neural Networks)\n",
        "params['message_calculation_class'] = 'GGNN'\n",
        "\n",
        "# Implements a deep Graph Neural Network\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "\n",
        "# Define the out put layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs={\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbHxfgaEyQZC",
        "outputId": "400371e6-6b76-437b-fc79-db87c928e2a9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_2 (TFOpLamb  ()                  0           ['input_12[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 20)           10000       ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  ()                  0           ['tf.math.reduce_max_2[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_2 (GNN)                    (None, 64)           171392      ['embedding_2[0][0]',            \n",
            "                                                                  'input_11[0][0]',               \n",
            "                                                                  'input_12[0][0]',               \n",
            "                                                                  'tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_2 (TFOpLa  (None, 64)          0           ['gnn_2[0][0]',                  \n",
            " mbda)                                                            'input_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            65          ['tf.math.segment_mean_2[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 181,457\n",
            "Trainable params: 181,457\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ],
      "metadata": {
        "id": "GBXSX_I13E-n"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Fitting"
      ],
      "metadata": {
        "id": "y2J49Gqd3JE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_E-i_533M6-",
        "outputId": "59e04ea6-b31f-49e5-a88d-ea8633a63587"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2381/2381 [==============================] - 185s 73ms/step - loss: 0.6321 - auc: 0.6936 - val_loss: 0.5867 - val_auc: 0.7472\n",
            "Epoch 2/10\n",
            "2381/2381 [==============================] - 182s 76ms/step - loss: 0.5701 - auc: 0.7728 - val_loss: 0.5441 - val_auc: 0.8020\n",
            "Epoch 3/10\n",
            "2381/2381 [==============================] - 170s 71ms/step - loss: 0.5323 - auc: 0.8108 - val_loss: 0.5185 - val_auc: 0.8224\n",
            "Epoch 4/10\n",
            "2381/2381 [==============================] - 142s 60ms/step - loss: 0.4959 - auc: 0.8404 - val_loss: 0.4964 - val_auc: 0.8503\n",
            "Epoch 5/10\n",
            "2381/2381 [==============================] - 144s 61ms/step - loss: 0.4656 - auc: 0.8622 - val_loss: 0.4492 - val_auc: 0.8754\n",
            "Epoch 6/10\n",
            "2381/2381 [==============================] - 137s 58ms/step - loss: 0.4286 - auc: 0.8848 - val_loss: 0.4046 - val_auc: 0.8985\n",
            "Epoch 7/10\n",
            "2381/2381 [==============================] - 137s 58ms/step - loss: 0.4006 - auc: 0.9002 - val_loss: 0.3801 - val_auc: 0.9109\n",
            "Epoch 8/10\n",
            "2381/2381 [==============================] - 149s 62ms/step - loss: 0.3734 - auc: 0.9138 - val_loss: 0.3798 - val_auc: 0.9161\n",
            "Epoch 9/10\n",
            "2381/2381 [==============================] - 136s 57ms/step - loss: 0.3534 - auc: 0.9226 - val_loss: 0.3324 - val_auc: 0.9318\n",
            "Epoch 10/10\n",
            "2381/2381 [==============================] - 138s 58ms/step - loss: 0.3320 - auc: 0.9315 - val_loss: 0.3136 - val_auc: 0.9460\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3f13e59a50>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## saving predictions results"
      ],
      "metadata": {
        "id": "pO6IA6nb3UT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test_data, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojDu43jJ3aQj",
        "outputId": "2b2c327e-2506-4b98-8e83-9c0a81d1ebed"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 14s 17ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saveResult(y_pred, 'trial_9.csv')"
      ],
      "metadata": {
        "id": "85ph_JHY3aBT"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thoughts and observations for trial 9, plan for trial 10:\n",
        "\n",
        "Using the same strcture of the previus model and the only diffrence was only Tuning the model by setting message passing style to GCNN and tuning its hyperparameter\n",
        "\n",
        "**The results**\n",
        "* Training : 93.15%  \n",
        "* kaggle public score : 84.13%\n",
        "\n",
        "oberservations : The results of the Third Trial was slightly better\n",
        "\n",
        "Plans :  Tuning the hyperparamters for the 7nth Trial."
      ],
      "metadata": {
        "id": "Y9YrUG-F3weX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial_10\n",
        "* Model : GNN \n",
        "* data : upsampled\n",
        "* Hidden_dim : 64 [was 32]\n",
        "* Batch_size : 16\n",
        "* epochs : 10\n",
        "\n",
        "**Tuning**\n",
        "* message_calculation_class : GNN_Edge_MLP [Trial_7 Tuning]\n",
        "* global_exchange_mode : 'mlp' [was 'gru']\n",
        "* layer_input_dropout_rate : 0.1 [was '0.2']\n"
      ],
      "metadata": {
        "id": "6EmE_AJw4GDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "7TI3aLc_4hkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# configure the hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "# \n",
        "# frist load the defualt hyperparameters of GNN_Edge_MLP\n",
        "params = GNN_Edge_MLP.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 64\n",
        "# configures the parameters that needed by GNN_Edge_MLP\n",
        "params['num_layers'] = 4\n",
        "params['dense_every_num_layers'] = 2\n",
        "params['residual_every_num_layers'] = 2\n",
        "params['use_inter_layer_layernorm'] = 2\n",
        "params['initial_node_representation_activation'] = 'tanh'\n",
        "params['dense_intermediate_layer_activation'] = 'tanh'\n",
        "params['message_calculation_class'] = 'RGCN'\n",
        "params['global_exchange_mode'] = 'mlp'   # has to be one of 'mean', 'mlp', 'gru'!\n",
        "params['global_exchange_every_num_layers'] = 1000\n",
        "params['global_exchange_weighting_fun'] = 'softmax'\n",
        "params['global_exchange_num_heads'] = 4\n",
        "params['global_exchange_dropout_rate'] = 0.2\n",
        "params['layer_input_dropout_rate'] = 0.1\n",
        "\n",
        "# Implements a deep Graph Neural Network\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "\n",
        "# Define the out put layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Un9wxfp4kRh",
        "outputId": "0b8c8f11-5f9c-4fee-c1aa-37ca5437b2a0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_13 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_3 (TFOpLamb  ()                  0           ['input_15[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 20)           10000       ['input_13[0][0]']               \n",
            "                                                                                                  \n",
            " input_14 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  ()                  0           ['tf.math.reduce_max_3[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_3 (GNN)                    (None, 64)           59136       ['embedding_3[0][0]',            \n",
            "                                                                  'input_14[0][0]',               \n",
            "                                                                  'input_15[0][0]',               \n",
            "                                                                  'tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_3 (TFOpLa  (None, 64)          0           ['gnn_3[0][0]',                  \n",
            " mbda)                                                            'input_15[0][0]']               \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1)            65          ['tf.math.segment_mean_3[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 69,201\n",
            "Trainable params: 69,201\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling model\n",
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ],
      "metadata": {
        "id": "cof1eqAH4u-4"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Fitting"
      ],
      "metadata": {
        "id": "eGkpV5hT4yMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmAgXRov44GH",
        "outputId": "74f5c113-16d3-4f75-de33-9c9ce581471a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2381/2381 [==============================] - 95s 38ms/step - loss: 0.5961 - auc: 0.7501 - val_loss: 0.5430 - val_auc: 0.8067\n",
            "Epoch 2/10\n",
            "2381/2381 [==============================] - 95s 40ms/step - loss: 0.5371 - auc: 0.8140 - val_loss: 0.5144 - val_auc: 0.8330\n",
            "Epoch 3/10\n",
            "2381/2381 [==============================] - 92s 39ms/step - loss: 0.5138 - auc: 0.8336 - val_loss: 0.4928 - val_auc: 0.8485\n",
            "Epoch 4/10\n",
            "2381/2381 [==============================] - 93s 39ms/step - loss: 0.4906 - auc: 0.8505 - val_loss: 0.5187 - val_auc: 0.8509\n",
            "Epoch 5/10\n",
            "2381/2381 [==============================] - 95s 40ms/step - loss: 0.4720 - auc: 0.8636 - val_loss: 0.4485 - val_auc: 0.8765\n",
            "Epoch 6/10\n",
            "2381/2381 [==============================] - 105s 44ms/step - loss: 0.4573 - auc: 0.8725 - val_loss: 0.4418 - val_auc: 0.8827\n",
            "Epoch 7/10\n",
            "2381/2381 [==============================] - 90s 38ms/step - loss: 0.4410 - auc: 0.8822 - val_loss: 0.4221 - val_auc: 0.8924\n",
            "Epoch 8/10\n",
            "2381/2381 [==============================] - 96s 40ms/step - loss: 0.4280 - auc: 0.8901 - val_loss: 0.4423 - val_auc: 0.8821\n",
            "Epoch 9/10\n",
            "2381/2381 [==============================] - 95s 40ms/step - loss: 0.4197 - auc: 0.8952 - val_loss: 0.4067 - val_auc: 0.9034\n",
            "Epoch 10/10\n",
            "2381/2381 [==============================] - 96s 40ms/step - loss: 0.4099 - auc: 0.9005 - val_loss: 0.3905 - val_auc: 0.9096\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3f08a53880>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## saving predictions results"
      ],
      "metadata": {
        "id": "guaX2Xl44_9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test_data, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogYzSmTl5C8u",
        "outputId": "b30aa7b3-5718-4e15-87aa-90955278f27d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 8s 10ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saveResult(y_pred, 'trial_10.csv')"
      ],
      "metadata": {
        "id": "NaZ0ZY_t5Cvq"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions"
      ],
      "metadata": {
        "id": "N4LCu_V6yr-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Based on the provided template, describe the format of the input file (sdf file)?\n",
        "\n",
        "Structure Data File (SDF) is the input file type. It gives details on a molecule's chemical composition. SDF files keep track of each atom's position inside a chemical molecule as well as its linkages. Expression serves as a boundary between several substances.\n",
        "\n",
        "Each sample begins with a header that provides information about the compound's name or title. Other parts contain details such as the number of Atoms, the version number, connections, etc. The elements of the compound are described by the atom block. The bonding structure of the chemical is described by the bond/edge block. These two blocks are employed to gather data about the compound and store it as edges and nodes. The provided atom from the chemical compound is at each node."
      ],
      "metadata": {
        "id": "JbsXGjZuyv90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.  What are the input tensors to the neural network model (their meaning, not just symbol)? What is each of their dims and their meaning (e.g. batch_size)?\n",
        "\n",
        "Data is made up of several characters called nodes like N C S O. Each batch has the shape [batch_size*max_len_nodes].\n",
        "\n",
        "It is made up of connections between nodes, such as 1-5, which refers to the edge between node 1 and node 5. Additionally, the edge's shape is [sum_of_all_edges,2].\n",
        "\n",
        "Each sample ends with the label value [1, -1]."
      ],
      "metadata": {
        "id": "khDHkk5czKZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. For each dim of gnn_out, what does it symbolize? For each dim of avg, what does it symbolize?\n",
        "* gnn_out :\n",
        "The shape of the gnn_out is [batch size node dimension, hidden layers], where batch size node dimension is the dimension of the tokenized vector for the full batch and input data node vector is the dimension. It represents the model's aggregation output for each hidden layer.\n",
        "\n",
        "* avg :\n",
        "Using the segmented ids, the segmented mean of the gnn_out is calculated. For each sample in the batch size, gnn out outputs [tokenized vector dimension, hidden layers]. The final output of the typical tensor has the following form: [batch size, hidden layer]. It is a technique for collecting data for each sample and displaying it as mean data."
      ],
      "metadata": {
        "id": "_vDSnd0xzma9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. What is the difference between segment_mean and tf.reduce_mean? For each dim of pred, what does it symbolize?\n",
        "\n",
        "* Segment_mean: calculates the average of data with identical segmentation identifiers.\n",
        "\n",
        "* reduce_mean: given parameters, computes the mean of a tensor's elements across all dimensions.\n",
        "\n",
        "* pred: The final result (pred) indicates whether a chemical component is likely to be active for cancer cells or not. Pred is [batch_size,1] shaped. As a result, the final output for each sample is a number that represents the probability that each chemical molecule will be active.\n",
        "\n"
      ],
      "metadata": {
        "id": "5TLl8d8fz_JC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. What is the motivation/theory/idea to use multiple gcn layers comparing to just one? How many layers were used in the template?\n",
        "The template implements the GCN network's default value for layer count, which is 4 as specified in the documentation. The Relational Graph Convolutional Networks (RGCN) is the standard message passing technique. A better model is produced by using numerous GCN, which aid in accurately capturing all of the graph complexity."
      ],
      "metadata": {
        "id": "JnQR4Gip0pv3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-GX-cs_syvPL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}